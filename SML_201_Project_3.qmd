---
title: "Project 3 - Taylor"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    embed-resources: true
    code-overflow: wrap
editor: visual
---

## Our Team

Fill the vector `our_team` with the full names (First Last) of each team member. Although this task is worth no points, failing to complete this task will result in a one-point deduction.

```{r our_team}
our_team = c('Arnold Jiang', 'John Woo', 'Willow Yang', 'Tong Dai')
our_team
```

## Our Seed

Fill the value `our_seed` with a calculated seed to precede all random sampling actions throughout this project. This way, your code can be executed for verification and reproduction. Although this task is worth no points, failing to complete this task will result in a five-point deduction.

```{r our_seed}
# calculate the seed to be the sum of the PUIDs of each teammate and then the remainder after dividing by 1746.
# for example, if you have two teammates with PUIDs 888888888 & 999999999,
our_seed = sum(920327399, 920400588, 920251660, 920293028) %% 1746
```

------------------------------------------------------------------------

## Introduction

Taylor Swift! Need we say more? While her name carries immense weight in the gravitas of pop culture, she is at the center of a vast network of artistic and entertainment icons.

In this project, we will focus on answering questions related to Taylor Swift and her world. Computational models and automated processes will be created from data related to the following two topics:

A.  Listening Analysis
B.  Song Recommendations

At the conclusion of each section, a written summary (5-10 sentences) of your work is required. The summaries should include:

-   commentary on the results of your output
-   potential enhancements to the models/processes
-   any answers to questions from prior tasks within the section

The project will be graded on a basis of 100 maximum points.

------------------------------------------------------------------------

## The Necessary Packages

Run this entire code chunk BEFORE proceeding to ensure that all subsequent code are recognized and executable.

```{r packages}
#| message: false
library(tidyverse)
library(highcharter)
library(visNetwork)
library(gt)
library(caTools)
library(glmnet)
library(htmltools)
```

------------------------------------------------------------------------

## A. Listening Analysis \[*50 pts total*\]

Perhaps there is no faster accumulation of data than that of music listening. Every time a song is played on a streaming platform, the listening details (who, what, when) of that play event are stored. With that data, much information can be obtained on user behavior, song preferences, and temporal trends. In this section, we will study the insights drawn from a sample of listening data.

#### A0. Data

-   `ts_plays`: a sampling of Taylor Swift songs played by a select group of Swifties.

```{r a0a}
#| message: false
#| echo: false

ts_plays = read_csv(file = 'https://www.dropbox.com/scl/fi/hx40zoj0o6f4hdmeb1mlf/ts_plays.csv?rlkey=yq8t0dp4q2aq1w9zkldwxigcr&st=87ozwgkn&&raw=1')
```

Data Dictionary - `ts_plays`

-   `play_dt`: the date and timestamp of when the playback of the song was initiated (formatted as "yyyy-mm-dd hh:mm:ss")
-   `swiftie`: the name of the user who played the song; note that each student's name will appear as one of the Swifties
-   `song`: the name of the song played

#### A1. Find the Swiftie \[*15 pts total*\]

Using the `ts_plays` data, find the `swiftie` for each of the categories below.

##### A1a. Most plays overall \[1 pt\]

```{r a1a}
# there's actually two swiftie with the same amount of highest overall plays

# Helper function for A1a and A1b
biggest_swiftie = function(data) {
  group_by(data, swiftie) |>
  summarise(total_plays = n()) |>
  arrange(desc(total_plays))
}

swiftie_most_plays = ts_plays |>
  biggest_swiftie() 

swiftie_most_plays

most_plays = swiftie_most_plays$total_plays[1]

swiftie_most_plays = swiftie_most_plays |>
  filter(total_plays == most_plays)


swiftie_most_plays$swiftie
```

##### A1b. Most plays between 11:00:00 AM and 2:49:59 PM inclusive \[2 pts\]

```{r a1b}
swiftie_most_plays_time = ts_plays |>
  mutate(play_time = format(as.POSIXct(play_dt), "%H:%M:%S")) |>
  filter(play_time >= "11:00:00", play_time <="14:49:59") |>
  biggest_swiftie()

most_plays_time = swiftie_most_plays_time$total_plays[1]

swiftie_most_plays_time <- swiftie_most_plays_time |>
  filter(total_plays == most_plays_time)

swiftie_most_plays_time$swiftie
```

##### A1c. Fewest plays of 'Cruel Summer' during the summer of 2024 \[3 pts\]

```{r a1c}
swiftie_least_plays_cruel = ts_plays |>
  filter(song == "Cruel Summer") |>
  mutate(date = as.Date(play_dt)) |>
  filter(date >= as.Date("2024-06-20"), date <= as.Date("2024-09-22")) |>
  group_by(swiftie) |>
  summarise(total_plays = n(), .groups = "drop") |>
  arrange(total_plays)

swiftie_least_plays_cruel

```

##### A1d. Least variance in monthly plays \[4 pts\]

```{r a1d}
swiftie_least_var_month = ts_plays |>
  mutate(month = month(as.Date(play_dt))) |>
  group_by(swiftie, month) |>
  summarize(monthly_plays = n(), .groups = "drop") |>
  group_by(swiftie) |>
  summarise(var_monthly_plays = var(monthly_plays), .groups = "drop") |>
  arrange(var_monthly_plays) |>
  slice(1)

swiftie_least_var_month$swiftie
```

##### A1e. Greatest slope coefficient in the linear regression of daily plays (x = day of year, y = daily plays) during December \[5 pts\]

```{r a1e}
dec_plays = ts_plays |>
    mutate(
        date = as.Date(play_dt),
        month = month(as.Date(play_dt)),
        day = yday(as.Date(play_dt))
    ) |>
    filter(month == 12) |>
    group_by(swiftie, date, day) |>
    summarize(daily_plays = n(), .groups = "drop")

slopes = dec_plays |>
    group_by(swiftie) |>
    summarize(slope = coef(lm(daily_plays ~ day))[2]) |>
    arrange(desc(slope)) |>
    slice(1)

slopes$swiftie
```

#### A2. Similar Swifties \[*10 pts*\]

Create a vector (called `our_songs`) that contains your team's songs played (`song`) with the frequency of the song being played (`freq`). Utilize this vector, along with `ts_plays`, to find the **five** other Swifties (not a team member) who are most similar to your team using the **Euclidean distance** measure.

You can create functions to streamline the processes of this problem.

```{r a2}
# Helper function for distance 
euclid = function(songs1, songs2) {
    all_songs = unique(c(songs1$song, songs2$song))
    v1 = v2 = setNames(numeric(length(all_songs)), all_songs)
    v1[songs1$song] = songs1$freq
    v2[songs2$song] = songs2$freq
    sqrt(sum((v1 - v2)^2))
}

our_songs = ts_plays |>
    filter(swiftie %in% our_team) |>
    count(song, name = "freq")

other_songs = ts_plays |>
    filter(!swiftie %in% our_team) |>
    count(swiftie, song, name = "freq")

swiftie_dist = other_songs |>
    group_by(swiftie) |>
    summarise(
    dist = euclid(
      our_songs,
      tibble(song = song, freq = freq)
    ),
    .groups = "drop"
    ) |>
    arrange(dist)

closest_swifties = swiftie_dist$swiftie[1:5]
closest_swifties
```

#### A3. Machine Learning Models \[*10 pts*\]

Use an 80/20 split of train/test from `ts_plays` to train and test these models:

-   `model1`: a **lasso** regression model (y = \# of songs played, x1 = hour of the day (0 to 23), x2 = weekend (0 or 1))
-   `model2` a **ridge** regression model (same variables as `model1`)

Comment in the summary about the results of these models.

```{r a3 mod1}
set.seed(our_seed)

ts_plays2 = ts_plays |>
    mutate(
        hour = as.integer(format(as.POSIXct(play_dt), "%H")),
        weekend = as.integer(weekdays(as.Date(play_dt)) %in% c("Saturday", "Sunday"))
    ) |>
    group_by(hour, weekend) |>
    summarise(num_plays = n(), .groups = "drop")

ts_plays2

split = sample.split(ts_plays2$num_plays, SplitRatio = 0.8)
train = subset(ts_plays2, split == TRUE)
test = subset(ts_plays2, split == FALSE)

x_train = as.matrix(train[, c("hour", "weekend")])
y_train = train$num_plays
x_test = as.matrix(test[, c("hour", "weekend")])
y_test = test$num_plays

cv_model1 = cv.glmnet(x_train, y_train, alpha = 1)
best_lambda = cv_model1$lambda.min

model1 = glmnet(x_train, y_train, alpha = 1, lambda = best_lambda)
pred1 = predict(model1, x_test, s = "lambda.min")
mse1 = mean((y_test - pred1)^2)

model1
mse1
```

```{r a3 mod2}
cv_model2 = cv.glmnet(x_train, y_train, alpha = 0)
best_lambda2 = cv_model2$lambda.min

model2 = glmnet(x_train, y_train, alpha = 0, lambda = best_lambda2)
pred2 = predict(model2, x_test, alpha = 0, lambda = best_lambda2)
mse2 = mean((y_test - pred2)^2)

model2
mse2
```

#### A4. Hypothesis Test \[*10 pts*\]

Conduct a hypothesis test to conclude if 'Love Story' is played more often than 'You Belong With Me' is played by the same Swiftie.

The data for this test must be the `ts_plays` data from a sample of 25 randomly-selected Swifties.

Use a significance of 0.05.

Comment in the summary about your conclusions from this test.

```{r a4}
set.seed(our_seed)

love_you = ts_plays |>
  filter(song %in% c('Love Story', 'You Belong With Me')) |>
  group_by(swiftie, song) |>
  summarize(n = n(), .groups = "drop") |>
  pivot_wider(names_from = song, values_from = n, values_fill = 0)
love_you
swiftie_samples = sample(love_you$swiftie, 25, replace=FALSE)

sampled = love_you |>
  filter(swiftie %in% swiftie_samples)

res = t.test(sampled$`Love Story`, sampled$`You Belong With Me`, 
                        paired = TRUE, alternative = "greater")
res

paste("Fail to Reject the Null Hyptohesis that Love Story plays more than You Belong With Me because p_val < 0.05")



```

#### A5. Summary \[*5 pts*\]

Write a concluding paragraph on your observations during the completion of this section. Contain all your words within the blockquote below by replacing the word 'Summary' with your text.

> Looking at the outputs of both models in A3, we observe that the lasso regression
model (model1) achieved a lower MSE of ~2033.56 while the ridge regression model 
(model2) achieved a higher MSE score of ~11392.65. This suggests that the lasso
regression model was a better for predicting the number of plays where hours and 
weekend are used as the predictors. From the Hypothesis test we achieved a p-value of 0.03167 which is less than the significance value of alpha = 0.05, which means we achieved a result that was not significant enough. Thus, we fail to reject the null hypothesis that “Love Story” was played significantly more.

------------------------------------------------------------------------

## B. Song Recommendations \[*50 pts total*\]

The science (not so much art) of stringing songs together using their metrics is at the heart of this section. Our goal is to determine what should come next based on defined logic. We will utilize the Camelot Wheel (explained [here](https://dj.studio/blog/camelot-wheel)) to guide us in our effort.

#### B0. Data

The `camelot` and `tracks` datasets will be used in this section.

```{r b0}
#| message: false
#| echo: false

camelot = read_csv(file = 'https://www.dropbox.com/scl/fi/lxldj4625pflbbjq9mw5e/ts_camelot.csv?rlkey=webhnlh6dq37k6ok2qy65591k&st=mix4dgom&raw=1')

tracks = read_csv(file = 'https://www.dropbox.com/scl/fi/285vnrhmbtzx0236j4lx1/ts_tracks.csv?rlkey=fk9vzhi5tx6j0l8j2kse9ujzk&st=zg0imlm3&raw=1')
```

Data Dictionary - `camelot`

-   `from`: the originating key
-   to`:` the destination key
-   `type`: the type of transition (Perfect, Up1, Down1, Scale)

Data Dictionary - `tracks`

-   `artist`: the artist(s) of the song
-   `song`: the song title
-   `energy`: the energy score (0 to 99) of the song
-   `danceability`: the danceability score (0 to 99) of the song
-   `happiness`: the happiness score (0 to 99) of the song
-   `cmlt`: the Camelot value of the song
-   `vid`: the url to video of the song (Taylor Swift songs only)

#### B1. The Camelot Wheel Network \[*10 pts*\]

![](https://www.dropbox.com/scl/fi/z20zmigzoowycla37b911/camelot.png?rlkey=42fwsqargov4qkm8t43wgkhpp&st=dra56rgh&raw=1){fig-align="center" width="3in"}

Generate a graph network (using `visNetwork`) showing the allowable paths for songs following the Camelot Wheel.

The graph must show arrows pointing toward the nodes to which a particular node can move. For example, for 12B, the allowable moves are to 12B, 12A, 11B, and 1B.

Use a color scheme similar to the wheel image above.

```{r b1}
color_palette <- c("#8df1c7", 
                   "#aaf499", 
                   "#bae269", 
                   "#e0d54f", 
                   "#f8bb95", 
                   "#fd8f9a", 
                   "#ee7ec7", 
                   "#e088e4",
                   "#c28bf1",
                   "#aabeee",
                   "#72e0ee",
                   "#60f1e7"
                   )

unique_nodes <- unique(camelot$from)

nodes <- data.frame(
  id = unique_nodes, 
  label = unique_nodes, 
  font.size = 10, 
  shape='circle')

nodes <- nodes %>%
  mutate(
    number = as.numeric(gsub("[[:alpha:]]", "", label)), 
    letter = gsub("[^a-zA-Z]", "", label),
    color = ifelse(letter == "A",
                   paste0(color_palette[number], '99'),
                   color_palette[number])
  )

nodesA <- nodes |>
  filter(letter == 'A') |>
  mutate(
    x = 200 * cos((2 * pi * number) / 12),
    y = 200 * sin((2 * pi * number) / 12)
  )

nodesB <- nodes |>
  filter(letter == 'B') |>
  mutate(
    x = 300 * cos((2 * pi * number) / 12),
    y = 300 * sin((2 * pi * number) / 12)
  )

edges <- data.frame(
  from = camelot$from, 
  to = camelot$to, 
  type = camelot$type)

visNetwork(rbind(nodesA, nodesB), 
           edges, 
           width = "100%",
           main = "Camelot Wheel Graph Network") |>
  visNodes(physics = FALSE) |> 
  visEdges(arrows = "to") |>
  visLayout(our_seed) 

```

#### B2. Setlist \[*15 pts*\]

Starting with a single song from tracks, create a list of **ten** songs such that each successive song follows this logic:

-   The next song must follow the Camelot Wheel rules.
-   The next song must increase in energy from the prior song. Note that a rapid rise in energy will limit the availability of songs in the later songs yet to be determined.
-   The next song must be one of the top 15 closest songs when measured by the Euclidean distance of danceability and happiness.
-   The smallest cosine similarity between any two songs in the setlist must be greater than 0.035. Cosine similarity must be measured using all of energy, danceability, and happiness.

Use `gt` to display the setlist of songs.

```{r b2}

# Helper Functions:
euclid = function(x, y) {
  sqrt((x$danceability - y$danceability)^2 + (x$happiness - y$happiness)^2)
}

cosine_sim = function(x, y) {
  sum(x * y) / (sqrt(sum(x^2)) * sqrt(sum(y^2)))
}

generate_setlist = function(start) {
  setlist = tracks |>
    filter(artist == start$artist, song == start$song)
  
  while(nrow(setlist < 10)) {
    cur = setlist[nrow(setlist), ]

    valid_cmlt = camelot |>
      filter(from == cur$cmlt) |>
      pull(to)
    
    candidates = tracks |>
      filter(
        cmlt %in% valid_cmlt,
        energy > cur$energy,
        !(artist == cur$artist & song == cur$song),
        !(paste(artist, song) %in% paste(setlist$artist, setlist$song))
      )
    if(nrow(candidates) == 0) break

    candidates_dist = candidates |>
      rowwise() |>
      mutate(
        dist = euclid(cur, pick(everything()))
      ) |>
      ungroup() |>
      arrange(dist) |>
      slice_head(n = 15)
    
    
  }
  setlist |> 
    select(artist, song, energy, danceability, happiness, cmlt)
}

start = tracks |>
  slice_sample(n = 1)

start
result = generate_setlist(start)
gt(result)


```

#### B3. Next Taylor Music Video \[*20 pts*\]

Using the `ts_video` function shown below, create a new function called `nextvid` that will take as input one of Taylor Swift songs (any song that has her name contained in `artist`) from tracks and return a video of a recommended song to follow the input song.

You can create your own logic to determine the next song using only the datasets provided in this project.

It is recommended that you generate a chart (using `highcharter`) to visualize the analysis.

Points will be awarded for the creativity in the usage of the data to recommend the next song.

```{r b30}

ts_video = function(s) {
  # find song in tracks
  ss = tracks |> filter(song == s)
  # create container to display video player
  player = div(
    align = 'center',
    # header for song title
    h4(ss$song),
    # the video
    tags$video(
      src = ss$vid,
      type = 'video/mp4',
      width = '90%',
      height = 'auto',
      controls = TRUE,
      autoplay = TRUE 
    )
  )
  return(player)
}
```

```{r b3}

# example of a video play
ts_video('ME!')
```

#### B4. Summary \[*5 pts*\]

Write a concluding paragraph on your observations during the completion of this section. Contain all your words within the blockquote below by replacing the word 'Summary' with your text.

> Summary

------------------------------------------------------------------------

## Z. Wrap Up

When you are ready to submit your project, follow these steps:

1.  Click the `Render` button to compile this document. An HTML file will be created in the folder containing this QMD file.

2.  Submit the HTML file to **Canvas** (not to Gradescope). Only one person per team needs to submit. Any confusion with multiple entries per team will result in point deductions in the final grade.
